# ğŸ—ï¸ Arquitetura RAG Multi-Agente - DocumentaÃ§Ã£o TÃ©cnica

## Conceitos Fundamentais

### O que Ã© RAG?

**RAG (Retrieval-Augmented Generation)** Ã© uma tÃ©cnica que combina:

1. **Retrieval**: Busca de informaÃ§Ãµes relevantes em uma base de conhecimento
2. **Augmentation**: Enriquecimento do prompt com o contexto recuperado
3. **Generation**: GeraÃ§Ã£o de resposta condicionada ao contexto

### Por que RAG ao invÃ©s de prompt simples?

| Aspecto | Prompt Simples | RAG |
|---------|----------------|-----|
| Base de conhecimento | Limitada ao training data do modelo | Atualizada com documentos prÃ³prios |
| PrecisÃ£o | Pode "alucinar" informaÃ§Ãµes | Respostas baseadas em fontes reais |
| Auditoria | DifÃ­cil rastrear origem | Logs mostram documentos usados |
| Escalabilidade | NÃ£o escala com novos conteÃºdos | Basta adicionar novos documentos |
| ContextualizaÃ§Ã£o | GenÃ©rica | EspecÃ­fica da organizaÃ§Ã£o |

## Componentes do Sistema

### 1. Embeddings Layer

**Arquivo**: `src/rag/embeddings/embeddings.ts`

**Responsabilidade**: Converter texto em vetores semÃ¢nticos

```typescript
generateEmbedding(text: string) -> number[] (1536 dimensÃµes)
```

**Como funciona**:
- Usa modelo `text-embedding-3-small` da OpenAI
- Cada palavra/conceito Ã© mapeado em um espaÃ§o vetorial de alta dimensÃ£o
- Textos semanticamente similares tÃªm vetores prÃ³ximos

**Exemplo**:
```
"Como resolver equaÃ§Ãµes?" â†’ [0.023, -0.451, 0.782, ..., 0.234]
"SoluÃ§Ã£o de equaÃ§Ãµes"     â†’ [0.019, -0.449, 0.779, ..., 0.231]
                              â†‘ Vetores prÃ³ximos = alta similaridade
```

### 2. Chunking Layer

**Arquivo**: `src/rag/ingest/chunker.ts`

**Responsabilidade**: Dividir documentos longos em pedaÃ§os processÃ¡veis

**Por que chunking?**
- Modelos tÃªm limite de contexto
- Chunks menores = busca mais precisa
- Permite recuperar apenas partes relevantes

**EstratÃ©gia**:
- Tamanho: ~800 caracteres (configurÃ¡vel)
- Overlap: 200 caracteres (evita perda de contexto)
- Quebra em pontuaÃ§Ã£o natural (frases completas)

```
Documento de 3000 caracteres
â†“
Chunk 1: [0-800]
Chunk 2: [600-1400]  â† overlap de 200
Chunk 3: [1200-2000]
Chunk 4: [1800-2600]
Chunk 5: [2400-3000]
```

### 3. Vector Store (pgvector)

**Arquivo**: `prisma/schema.prisma`

**Responsabilidade**: Armazenar e buscar embeddings eficientemente

**Schema**:
```prisma
model AgentDocument {
  id        String
  agentId   String
  content   String
  metadata  Json
  embedding vector(1536)  â† Tipo especial pgvector
}
```

**Ãndice IVFFlat**:
```sql
CREATE INDEX agent_documents_embedding_idx 
ON agent_documents 
USING ivfflat (embedding vector_cosine_ops) 
WITH (lists = 100);
```

**Como funciona a busca**:
```sql
-- Buscar top-5 documentos mais similares
SELECT *, 
  1 - (embedding <=> '[query_vector]'::vector) as similarity
FROM agent_documents
WHERE agent_id = 'professor_pitagoras'
ORDER BY embedding <=> '[query_vector]'::vector
LIMIT 5;
```

### 4. Retriever

**Arquivo**: `src/rag/retriever/retriever.ts`

**Responsabilidade**: Orquestrar a busca vetorial

**Fluxo**:
```
1. Recebe query do usuÃ¡rio
2. Gera embedding da query
3. Busca no pgvector usando similaridade de cosseno
4. Retorna top-k documentos com scores
```

**Output**:
```typescript
[
  {
    id: "uuid",
    content: "EquaÃ§Ãµes do primeiro grau...",
    metadata: { topic: "Ãlgebra", difficulty: "bÃ¡sico" },
    similarity: 0.87  // 87% de similaridade
  },
  // ... mais documentos
]
```

### 5. Generator

**Arquivo**: `src/rag/generator/generator.ts`

**Responsabilidade**: Gerar resposta usando Claude com contexto

**Prompt Engineering**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SYSTEM PROMPT              â”‚
â”‚  (Persona do agente)        â”‚
â”‚  - InstruÃ§Ãµes               â”‚
â”‚  - Tom de voz               â”‚
â”‚  - Diretrizes               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         +
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CONTEXTO RECUPERADO        â”‚
â”‚  --- Documento 1 ---        â”‚
â”‚  Fonte: Material Atomize    â”‚
â”‚  [conteÃºdo]                 â”‚
â”‚  --- Documento 2 ---        â”‚
â”‚  [conteÃºdo]                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         +
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PERGUNTA DO ALUNO          â”‚
â”‚  "Como resolver equaÃ§Ãµes?"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    Claude Sonnet 3.5
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RESPOSTA CONTEXTUALIZADA   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**DiferenÃ§a crucial**:
- **Sem RAG**: Claude responde apenas com conhecimento geral
- **Com RAG**: Claude responde baseado nos materiais Atomize especÃ­ficos

### 6. Logger

**Arquivo**: `src/rag/logger/logger.ts`

**Responsabilidade**: Auditoria e mÃ©tricas

**O que Ã© registrado**:
```typescript
{
  agentId: "professor_pitagoras",
  userId: "aluno123",
  question: "Como resolver equaÃ§Ãµes?",
  answer: "Para resolver...",
  retrievedDocIds: ["uuid1", "uuid2", "uuid3"],
  retrievalScores: [0.87, 0.79, 0.71],  â† PROVA DO RETRIEVAL
  responseTimeMs: 1234,
  tokensUsed: 856,
  modelUsed: "claude-sonnet-3-5-20241022"
}
```

## Fluxo End-to-End

### Pipeline de IngestÃ£o (Offline)

```
1. Carregar documentos fonte
   â””â”€â–º loadSampleDocuments()

2. Dividir em chunks
   â””â”€â–º chunkText() â†’ chunks[]

3. Gerar embeddings
   â””â”€â–º generateEmbeddingsBatch(chunks) â†’ embeddings[]

4. Armazenar no banco
   â””â”€â–º INSERT INTO agent_documents
       (content, embedding, metadata)
```

### Pipeline de Query (Online)

```
1. Receber requisiÃ§Ã£o
   POST /api/agents/query
   { agentId, message, userId }

2. Validar agente
   â””â”€â–º isValidAgentId()
   â””â”€â–º getAgentConfig()

3. RETRIEVAL
   â””â”€â–º generateEmbedding(message)
   â””â”€â–º retrieveDocuments(agentId, embedding, topK=5)
       â†’ documents[] com similarity scores

4. GENERATION
   â””â”€â–º buildRAGPrompt(agentConfig, message, documents)
   â””â”€â–º anthropic.messages.create()
       â†’ answer

5. LOGGING
   â””â”€â–º logQuery(query, result, documents)

6. Retornar resposta
   { answer, sources, metrics }
```

## Similaridade de Cosseno

**Como Ã© calculada**:
```
similarity = cos(Î¸) = (A Â· B) / (||A|| Ã— ||B||)

Onde:
- A = vetor da query
- B = vetor do documento
- Â· = produto escalar
- || || = norma (magnitude)
```

**InterpretaÃ§Ã£o**:
- `1.0` = IdÃªntico
- `0.8-0.9` = Muito similar
- `0.6-0.7` = Relacionado
- `< 0.5` = Pouco relacionado

**Vantagem**: Independente da magnitude dos vetores, foca na direÃ§Ã£o (semÃ¢ntica).

## Agentes Especializados

### Como funcionam?

Cada agente tem:

1. **ID Ãºnico**: `professor_pitagoras`
2. **System Prompt**: InstruÃ§Ãµes detalhadas de comportamento
3. **Base de conhecimento**: Documentos filtrados por `agent_id`
4. **Metadata**: PÃºblico-alvo, especialidades

### Isolamento

```sql
-- Agente 1 sÃ³ vÃª seus documentos
SELECT * FROM agent_documents 
WHERE agent_id = 'professor_pitagoras';

-- Agente 2 sÃ³ vÃª os dele
SELECT * FROM agent_documents 
WHERE agent_id = 'dra_clarice_lispector';
```

Isso garante que:
- Professor PitÃ¡goras fala de matemÃ¡tica
- Dra. Clarice fala de portuguÃªs
- NÃ£o hÃ¡ "contaminaÃ§Ã£o" entre domÃ­nios

## Escalabilidade

### Adicionar novo agente:

```typescript
// 1. Criar configuraÃ§Ã£o
export const profMaryCurie: AgentConfig = {
  id: 'prof_mary_curie',
  name: 'ProfÂª. Mary Curie',
  specialty: ['CiÃªncias', 'QuÃ­mica', 'FÃ­sica'],
  systemPrompt: `VocÃª Ã© a ProfÂª. Mary Curie...`,
  // ...
};

// 2. Registrar no Ã­ndice
export const AGENTS = {
  // ... existentes
  prof_mary_curie: profMaryCurie,
};

// 3. Ingerir documentos
const docs = loadDocumentsForCiencias();
await ingestDocuments('prof_mary_curie', docs);
```

Pronto! O agente estÃ¡ disponÃ­vel sem alterar lÃ³gica de retrieval/generation.

## Performance

### OtimizaÃ§Ãµes implementadas:

1. **Ãndice IVFFlat**: Busca ~10x mais rÃ¡pida que forÃ§a bruta
2. **Batch embeddings**: Processa 100 textos por vez
3. **Caching implÃ­cito**: Prisma mantÃ©m conexÃµes abertas
4. **Top-K limitado**: Apenas documentos mais relevantes

### Benchmarks esperados:

- Embedding generation: ~200ms
- Vector search (pgvector): ~50ms
- Claude generation: ~2-4s (depende do tamanho da resposta)
- **Total**: ~2.5-4.5s por query

## SeguranÃ§a e ValidaÃ§Ã£o

### Input validation (Zod):
```typescript
const QueryRequestSchema = z.object({
  agentId: z.string().min(1),
  message: z.string().min(1).max(2000),  // Limita tamanho
  // ...
});
```

### SanitizaÃ§Ã£o:
- Prisma protege contra SQL injection
- API valida agentId contra lista permitida
- Rate limiting recomendado em produÃ§Ã£o

## Troubleshooting

### "Base de conhecimento vazia"
- Execute `npm run ingest`
- Verifique logs: documentos foram inseridos?

### "Similaridade muito baixa"
- Documentos podem nÃ£o cobrir o tÃ³pico
- Considere adicionar mais materiais
- Verifique se agentId estÃ¡ correto

### "Erro de conexÃ£o com banco"
- Verifique DATABASE_URL
- Confirme que pgvector estÃ¡ instalado
- Rode migrations: `npm run prisma:migrate`

---

**Esta arquitetura permite**:
âœ… Respostas baseadas em fontes reais (nÃ£o alucina)
âœ… Auditoria completa (logs com retrieval scores)
âœ… MÃºltiplos agentes especializados isolados
âœ… Escalabilidade (novos agentes e documentos)
âœ… Performance aceitÃ¡vel para produÃ§Ã£o
